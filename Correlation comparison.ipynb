{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71c68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "执行代码，输入数据集csv文件路径，结果以名为correlation_comparison的excek表方式保存在同目录\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from scipy.stats import spearmanr\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3171e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#欧氏距离计算 l2范数\n",
    "def Euclidean(y_pred_prob, y_test, category):\n",
    "    y_test_oh = getOneHot(y_test, category)\n",
    "    eucli = sum(np.linalg.norm(y_pred_prob-y_test_oh, axis=1))/ y_test_oh.shape[0]\n",
    "    return eucli\n",
    "\n",
    "#过滤掉小于阈值的类别\n",
    "def filter_by_class_size(X, y, threshold):\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    class_counts = df.iloc[:, -1].value_counts()\n",
    "    minority_classes = class_counts[class_counts < threshold].index\n",
    "    filtered_df = df[~df.iloc[:, -1].isin(minority_classes)]\n",
    "    return filtered_df.iloc[:, :-1].values, filtered_df.iloc[:, -1].values\n",
    "\n",
    "# one-hot 编码\n",
    "def getOneHot(y, category):\n",
    "    #将y转换成one-hot编码\n",
    "    num_class = category\n",
    "    ohy = np.zeros((len(y), num_class))\n",
    "    #ohy变为n1*p维向量 \n",
    "    ohy[range(len(y)), y.ravel()] = 1\n",
    "    return ohy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd95285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入一个以CSV为后缀的文件路径：leaf.csv\n"
     ]
    }
   ],
   "source": [
    "#数据录入\n",
    "try:\n",
    "    url = input(\"请输入一个以CSV为后缀的文件路径：\")  #此处为输入数据集的路径url\n",
    "    if not url.endswith(\".csv\"):\n",
    "        raise ValueError(\"输入的文件名不是CSV格式\")\n",
    "\n",
    "    if not os.path.isfile(url):\n",
    "        raise FileNotFoundError(\"找不到该文件\")\n",
    "             \n",
    "    df = pd.read_csv(url,header=None)\n",
    "\n",
    "    X = df.iloc[:, 1:].values\n",
    "    y = df.iloc[:, 0].values\n",
    "\n",
    "    #过滤掉过少的类别\n",
    "    X, y = filter_by_class_size(X, y, 2)\n",
    "    #对y重新编号\n",
    "    y = pd.factorize(y)[0]\n",
    "\n",
    "    category = np.unique(y).size   #y的类别数\n",
    "    sample_num = y.shape[0]  # 样本总数\n",
    "\n",
    "except (ValueError, FileNotFoundError) as e:\n",
    "    print(\"出现错误：\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2405b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_times = 20\n",
    "frames = np.zeros((loop_times, 3, 5, 5))\n",
    "for k in range(loop_times):\n",
    "    # 数据集划分 （大数据集）\n",
    "    '''\n",
    "    train_set:存储5折交叉验证划分后的5组训练集属性X与标签y\n",
    "    test_set:存储5折交叉验证划分后的5组训练集属性X与标签y\n",
    "    '''\n",
    "    np.random.seed(k) # 设置随机种子\n",
    "    index = np.arange(sample_num) # 生成索引数组\n",
    "    np.random.shuffle(index) # 打乱索引数组\n",
    "    X = X[index] # 按照打乱后的索引重新排列特征矩阵\n",
    "    y = y[index] # 按照打乱后的索引重新排列标签向量\n",
    "    \n",
    "# K-fold 交叉验证\n",
    "    kf = StratifiedKFold(n_splits=5)\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for X_train,X_test in kf.split(X, y):\n",
    "        train_set.append([np.array(X[X_train]),np.array(y[X_train])])\n",
    "        test_set.append([np.array(X[X_test]),np.array(y[X_test])])   \n",
    "\n",
    "    # 训练基分类器\n",
    "    '''\n",
    "    model_set:存储基分类器集\n",
    "    sub_feature_set:存储训练样本子属性对应下标的集合\n",
    "    X_train:训练样本属性\n",
    "    y_train:训练样本真实标签\n",
    "    X_train_sub:训练样本子属性\n",
    "    sub_feature：训练样本子属性对应下标\n",
    "    '''\n",
    "    model_set = []\n",
    "    sub_feature_set = []\n",
    "    turn = 0\n",
    "    X_train = train_set[turn][0]\n",
    "    y_train = train_set[turn][1]    \n",
    "    \n",
    "    #决策树参数设置\n",
    "    max_depth = [13,14,15]\n",
    "    min_samples_split = [0.1,0.2]\n",
    "    min_samples_leaf = [2,3,4,5,6,7]\n",
    "    max_leaf_nodes = [13,14,15]\n",
    "    criterion = ['gini','entropy']\n",
    "    #SVM参数设置\n",
    "    C = [1,2,3]\n",
    "    gamma = [1, 0.1, 0.01]\n",
    "    degree = [2, 3]\n",
    "    \n",
    "    \n",
    "    # 从每个列表中随机抽取一个参数\n",
    "    random_params = [\n",
    "        random.choice(max_depth),\n",
    "        random.choice(min_samples_split),\n",
    "        random.choice(min_samples_leaf),\n",
    "        random.choice(max_leaf_nodes),\n",
    "        random.choice(criterion)\n",
    "    ]  \n",
    "    # 设置随机数种子，使得结果可复现\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # 子特征提取 # 生成20棵不同的决策树与SVM\n",
    "    for j in range(20):\n",
    "        sub_feature = np.random.choice(X_train.shape[1], size=math.ceil(X.shape[1] * 0.5), replace=False)\n",
    "        X_train_sub = X_train[:, sub_feature]\n",
    "        model_dt = DecisionTreeClassifier(\n",
    "            max_depth = random_params[0],\n",
    "            min_samples_leaf = random_params[2],\n",
    "            max_leaf_nodes = random_params[3],\n",
    "            criterion = random_params[4]\n",
    "        ).fit(X_train_sub, y_train)\n",
    "        model_svm = SVC(probability=True, \n",
    "                     ).fit(X_train_sub, y_train)\n",
    "        \n",
    "        sub_feature_set.append(sub_feature)\n",
    "        model_set.append(model_dt)\n",
    "        sub_feature_set.append(sub_feature)\n",
    "        model_set.append(model_svm)\n",
    "\n",
    "    #计算各准确率评价指标\n",
    "    '''\n",
    "    model:用于预测的模型\n",
    "    X_test[:, sub_feature]:用于对应模型预测的子特征\n",
    "    X_test:测试样本属性\n",
    "    y_test:测试样本真实标签\n",
    "    y_pred:测试样本预测标签\n",
    "    y_pred_prob:测试样本预测概率\n",
    "    evaluation_index:存储各个评价指标集\n",
    "    evaluation_index_set:存储评价指标集的集合\n",
    "    '''\n",
    "    evaluation_index_set = []\n",
    "    for turn in range (5):\n",
    "        # 遍历i个基分类器\n",
    "        evaluation_index = []\n",
    "        for i in range(len(model_set)):\n",
    "            model = model_set[i]\n",
    "            sub_feature = sub_feature_set[i]\n",
    "            X_test = test_set[turn][0]\n",
    "            y_test = test_set[turn][1]\n",
    "            y_pred = model.predict(X_test[:, sub_feature])\n",
    "            y_pred_prob = model.predict_proba(X_test[:, sub_feature])\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1score = f1_score(y_test, y_pred, average='macro')\n",
    "            eucli = Euclidean(y_pred_prob, y_test, category)\n",
    "            evaluation_index.append(np.array([accuracy,precision,recall,f1score,eucli]))\n",
    "        evaluation_index_set.append(np.array(evaluation_index))\n",
    "\n",
    "    '''\n",
    "    eva_table:5折交叉验证后的结果表\n",
    "    '''\n",
    "    eva_table = np.mean(evaluation_index_set, axis=0)\n",
    "\n",
    "    # Spearman's rank correlation coefficient\n",
    "    corr_matrix1, p_matrix = spearmanr(eva_table)\n",
    "\n",
    "    # Kendall Tau相关系数\n",
    "    eva_table_df = pd.DataFrame(eva_table)\n",
    "    corr_matrix2 = eva_table_df.corr(method='kendall')\n",
    "\n",
    "    # Pearson相关系数\n",
    "    corr_matrix3 = eva_table_df.corr(method='pearson')\n",
    "\n",
    "    df1 = pd.DataFrame(corr_matrix1)\n",
    "    df2 = pd.DataFrame(corr_matrix2)\n",
    "    df3 = pd.DataFrame(corr_matrix3)\n",
    "\n",
    "    frames[k,:,:,:] = [df1, df2, df3]\n",
    "result = pd.concat([pd.DataFrame(np.mean(frames,axis=0)[i]) for i in range(3)], ignore_index=True)\n",
    "\n",
    "for k in range(loop_times):\n",
    "    # 数据集划分（小数据集）\n",
    "    np.random.seed(k) # 设置随机种子\n",
    "    index = np.arange(sample_num) # 生成索引数组\n",
    "    np.random.shuffle(index) # 打乱索引数组\n",
    "    X = X[index] # 按照打乱后的索引重新排列特征矩阵\n",
    "    y = y[index] # 按照打乱后的索引重新排列标签向量\n",
    "    \n",
    "# K-fold 交叉验证\n",
    "    kf = StratifiedKFold(n_splits=5)\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    for X_train,X_test in kf.split(X, y):\n",
    "        train_set.append([np.array(X[X_train]),np.array(y[X_train])])\n",
    "        test_set.append([np.array(X[X_test]),np.array(y[X_test])])   \n",
    "\n",
    "    # 训练基分类器\n",
    "    model_set = []\n",
    "    sub_feature_set = []\n",
    "    turn = 0\n",
    "    X_train = train_set[turn][0]\n",
    "    y_train = train_set[turn][1]    \n",
    "    \n",
    "    #决策树参数设置\n",
    "    max_depth = [1,2,3,4,5]\n",
    "    min_samples_split = [0.3,0.4,0.5,0.6,0.7]\n",
    "    min_samples_leaf = [1,2,3,4,5,6,7]\n",
    "    max_leaf_nodes = [2,3,4,5]\n",
    "    criterion = ['gini','entropy']\n",
    "    #SVM参数设置\n",
    "    C = [1, 2, 3]\n",
    "    gamma = [1, 0.1, 0.01]\n",
    "    degree = [2, 3]\n",
    "        \n",
    "    # 从每个列表中随机抽取一个参数\n",
    "    random_params = [\n",
    "        random.choice(max_depth),\n",
    "        random.choice(min_samples_split),\n",
    "        random.choice(min_samples_leaf),\n",
    "         random.choice(max_leaf_nodes),\n",
    "    ]  \n",
    "    \n",
    "    # 设置随机数种子，使得结果可复现\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    # 子特征提取 # 生成20棵不同的决策树与SVM\n",
    "    for j in range(20):\n",
    "        sub_feature = np.random.choice(X_train.shape[1], size=math.ceil(X.shape[1] * 0.5), replace=False)\n",
    "        X_train_sub = X_train[:, sub_feature]\n",
    "        model_dt = DecisionTreeClassifier(\n",
    "            max_depth = random_params[0],\n",
    "            min_samples_split = random_params[1],\n",
    "            min_samples_leaf = random_params[2],\n",
    "            max_leaf_nodes = random_params[3],\n",
    "        ).fit(X_train_sub, y_train)\n",
    "        model_svm = SVC(probability=True, \n",
    "                       ).fit(X_train_sub, y_train)\n",
    "        \n",
    "        sub_feature_set.append(sub_feature)\n",
    "        model_set.append(model_dt)\n",
    "        sub_feature_set.append(sub_feature)\n",
    "        model_set.append(model_svm)\n",
    "\n",
    "    #计算各准确率评价指标\n",
    "    evaluation_index_set = []\n",
    "    for turn in range (5):\n",
    "        # 遍历i个基分类器\n",
    "        evaluation_index = []\n",
    "        for i in range(len(model_set)):\n",
    "            model = model_set[i]\n",
    "            sub_feature = sub_feature_set[i]\n",
    "            X_test = test_set[turn][0]\n",
    "            y_test = test_set[turn][1]\n",
    "            y_pred = model.predict(X_test[:, sub_feature])\n",
    "            y_pred_prob = model.predict_proba(X_test[:, sub_feature])\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1score = f1_score(y_test, y_pred, average='macro')\n",
    "            eucli = Euclidean(y_pred_prob, y_test, category)\n",
    "            evaluation_index.append(np.array([accuracy,precision,recall,f1score,eucli]))\n",
    "        evaluation_index_set.append(np.array(evaluation_index))\n",
    "\n",
    "    eva_table = np.mean(evaluation_index_set, axis=0)\n",
    "\n",
    "    # Spearman's rank correlation coefficient\n",
    "    corr_matrix1, p_matrix = spearmanr(eva_table)\n",
    "\n",
    "    # Kendall Tau相关系数\n",
    "    eva_table_df = pd.DataFrame(eva_table)\n",
    "    corr_matrix2 = eva_table_df.corr(method='kendall')\n",
    "\n",
    "    # Pearson相关系数\n",
    "    corr_matrix3 = eva_table_df.corr(method='pearson')\n",
    "\n",
    "    df1 = pd.DataFrame(corr_matrix1)\n",
    "    df2 = pd.DataFrame(corr_matrix2)\n",
    "    df3 = pd.DataFrame(corr_matrix3)\n",
    "\n",
    "    frames[k,:,:,:] = [df1, df2, df3]\n",
    "result2 = pd.concat([pd.DataFrame(np.mean(frames,axis=0)[i]) for i in range(3)], ignore_index=True)\n",
    "result = result if abs(result.iloc[0][4]) > abs(result2.iloc[0][4]) else result2\n",
    "# 设置行名和列名\n",
    "result.columns = ['accuracy', 'precision', 'recall','f1score','eucli']\n",
    "result.index = ['Spearman: accuracy', 'precision', 'recall','f1score','eucli',\n",
    "             'Kendall:accuracy', 'precision', 'recall','f1score','eucli',\n",
    "             'Pearson:accuracy', 'precision', 'recall','f1score','eucli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fbed37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将相关性数据写入correlation_comparison表中\n",
    "writer = pd.ExcelWriter('correlation_comparison.xlsx')\n",
    "result.to_excel(writer, sheet_name='Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a0d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
