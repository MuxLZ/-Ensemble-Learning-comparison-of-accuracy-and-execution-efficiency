{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74cd82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "执行代码，输入数据集csv文件路径，准确度与时间开销结果输出在末尾\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad322ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot 编码\n",
    "def getOneHot(y, category):\n",
    "    #将y转换成one-hot编码\n",
    "    num_class = category\n",
    "    ohy = np.zeros((len(y), num_class))\n",
    "    #ohy变为n1*p维向量 \n",
    "    ohy[range(len(y)), y.ravel()] = 1\n",
    "    return ohy\n",
    "\n",
    "#过滤掉小于阈值的类别\n",
    "def filter_by_class_size(X, y, threshold):\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    class_counts = df.iloc[:, -1].value_counts()\n",
    "    minority_classes = class_counts[class_counts < threshold].index\n",
    "    filtered_df = df[~df.iloc[:, -1].isin(minority_classes)]\n",
    "    return filtered_df.iloc[:, :-1].values, filtered_df.iloc[:, -1].values\n",
    "\n",
    "# 数据概率化--[0~1]\n",
    "def normalize(data):\n",
    "    return abs(data) / np.sum(abs(data),axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35d282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#基分类器分类准确度\n",
    "def get_base_predict(X, y, model_set):\n",
    "    Accscore = []\n",
    "    y_pred = []\n",
    "    for model in model_set:\n",
    "        y_pred.append(model.predict_proba(X))\n",
    "        Accscore.append(accuracy_score(model.predict(X), y))\n",
    "    return Accscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf5a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#欧氏距离计算\n",
    "def Euclidean(X_train_weight,y_train_weight,X_test,y_test,model_Set):\n",
    "    m = 3   #分类器个数\n",
    "    res_all_set = []\n",
    "    train_weight_prediction_proba = []\n",
    "    # 训练集上的预测概率\n",
    "    train_weight_prediction_proba = [pd.DataFrame(model.predict_proba(X_train_weight)) for model in model_Set]\n",
    "    y_train_weight_oh = getOneHot(y_train_weight, category)\n",
    "    # 测试集上的预测概率\n",
    "    test_prediction_proba = [pd.DataFrame(model.predict_proba(X_test)) for model in model_Set]\n",
    "    y_test_oh = getOneHot(y_test, category)\n",
    "       \n",
    "    train_weight_prediction_proba_matrix = np.stack(train_weight_prediction_proba, axis=0) # shape: (M, N, P)\n",
    "    y_train_weight_oh_matrix = np.stack(y_train_weight_oh, axis=0) # shape: (M, N, P)\n",
    "    ## 数据准备阶段 完毕  \n",
    "    ## ----------此处开始计算时间----------\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    res_all_set = []\n",
    "    for i in range(m):\n",
    "        a_ij = np.sum(train_weight_prediction_proba_matrix * train_weight_prediction_proba_matrix[i], axis=(1,2)) # shape: (M,)\n",
    "        b_i = np.sum(y_train_weight_oh_matrix * train_weight_prediction_proba_matrix[i], axis=(0,1)) # shape: (M,)\n",
    "        res_all_set.append((a_ij, b_i))\n",
    "        \n",
    "    a = np.stack([res_all_set[i][0] for i in range(m)], axis=1) # shape: (M, M)\n",
    "    b = np.stack([res_all_set[i][1] for i in range(m)], axis=0) # shape: (M, 1)\n",
    "    w = LinearRegression(fit_intercept=False).fit(a,b).coef_\n",
    "    # 权重归一\n",
    "    ww = w / sum(w)\n",
    "    \n",
    "    addw_pred_test = np.sum(\n",
    "        [ww[0]*test_prediction_proba[0], ww[1]*test_prediction_proba[1],\n",
    "         ww[2]*test_prediction_proba[2]],axis=0)\n",
    "    \n",
    "    y_hat_test = np.argmax(addw_pred_test, axis=1)\n",
    "    \n",
    "    test_score = accuracy_score(y_test,y_hat_test)\n",
    "    \n",
    "    ## ----------此处结束计算时间----------\n",
    "    end_time = time.perf_counter()\n",
    "    timekeeping_E.append(end_time - start_time)\n",
    "    \n",
    "    return test_score\n",
    "\n",
    "#平均权重计算\n",
    "def averageWeight(X_train_weight,y_train_weight,X_test,y_test,model_Set):\n",
    "    w = [1/3.0,1/3.0,1/3.0]\n",
    "     # 训练集上的预测概率\n",
    "    train_weight_prediction_proba = [pd.DataFrame(model.predict_proba(X_train_weight)) for model in model_Set]\n",
    "    test_prediction_proba = [pd.DataFrame(model.predict_proba(X_test)) for model in model_Set]\n",
    "    \n",
    "    addw_pred_train = np.sum(\n",
    "        [w[0]*train_weight_prediction_proba[0], w[1]*train_weight_prediction_proba[1],\n",
    "         w[2]*train_weight_prediction_proba[2]],axis=0)\n",
    "    addw_pred_test = np.sum(\n",
    "        [w[0]*test_prediction_proba[0], w[1]*test_prediction_proba[1],\n",
    "         w[2]*test_prediction_proba[2]],axis=0)\n",
    "    \n",
    "    y_hat_train = np.argmax(addw_pred_train, axis=1)  \n",
    "    y_hat_test = np.argmax(addw_pred_test, axis=1)\n",
    "    \n",
    "    train_score = accuracy_score(y_train_weight,y_hat_train)\n",
    "    test_score = accuracy_score(y_test,y_hat_test)\n",
    "    \n",
    "    return train_score,test_score\n",
    "\n",
    "\n",
    "#简单权重表计算\n",
    "def simple_computer_weight(X_train_weight,y_train_weight,X_test,y_test,model_Set): \n",
    "    train_weight_prediction_proba = []\n",
    "    test_prediction_proba = []\n",
    "    \n",
    "    for model in model_Set:\n",
    "        train_weight_prediction_proba.append(pd.DataFrame(model.predict_proba(X_train_weight)))\n",
    "        test_prediction_proba.append(pd.DataFrame(model.predict_proba(X_test)))\n",
    "    \n",
    "    y_train_weight_oh = getOneHot(y_train_weight, category).reshape(-1,1)\n",
    "    y_test_oh = getOneHot(y_test, category).reshape(-1,1)\n",
    "    \n",
    "    train_weight_stack = np.hstack([proba.values.reshape(-1, 1) for proba in train_weight_prediction_proba])\n",
    "    test_stack = np.hstack([proba.values.reshape(-1, 1) for proba in test_prediction_proba]) \n",
    "    \n",
    "    lr_final = LinearRegression(fit_intercept=False).fit(train_weight_stack, y_train_weight_oh)\n",
    "    coef = lr_final.coef_[0]\n",
    "    intercept = lr_final.intercept_\n",
    "    # 权重归一\n",
    "    ww = np.zeros(3)\n",
    "    ww[0] = coef[0]/sum(coef)\n",
    "    ww[1] = coef[1]/sum(coef)\n",
    "    ww[2] = coef[2]/sum(coef)\n",
    "    \n",
    "    train_score,addw_pred_train = calcSW_accuracy(ww, intercept, train_weight_stack, y_train_weight)\n",
    "    test_score,addw_pred_test = calcSW_accuracy(ww, intercept, test_stack, y_test)\n",
    "    return train_score,test_score\n",
    "\n",
    "def calcSW_accuracy(coef, intercept, prova, y):\n",
    "    arr = prova.dot(coef) + intercept\n",
    "    tmparr = np.split(arr, len(y))\n",
    "    # list 转为numpy数组\n",
    "    tmparr = np.array(tmparr)\n",
    "    # 概率化处理\n",
    "    tmparr = normalize(tmparr)\n",
    "    max_index = np.argmax(tmparr, axis=1)\n",
    "    return accuracy_score(max_index, y),tmparr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d49efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneVsOthers StackingC\n",
    "def StackingC(X, y, X_test,y_test):   \n",
    "    n_classifiers = 3\n",
    "    n_features = X.shape[1]\n",
    "    n_classes = int(n_features/n_classifiers)\n",
    "    cols = np.array(range(n_features)).reshape(n_classifiers, n_classes).T\n",
    "    XL = []\n",
    "    XLT = []\n",
    "    # for each column index in cols, create a ColumnSelector and fit_transform X\n",
    "    XL = [ColumnSelector(cols=c).fit_transform(X) for c in cols]\n",
    "    XLT = [ColumnSelector(cols=c).fit_transform(X_test) for c in cols]\n",
    "    coef = np.zeros((n_classes, 3))  # 分类器个数==coef个数\n",
    "    intercept = np.zeros(n_classes)   \n",
    "    \n",
    "    ## ----------此处开始计算时间----------\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        # create a new label vector where the current class is 1 and the rest are 0\n",
    "        y_bin = np.where(y == i, 1, 0)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(XL[i], y_bin)        \n",
    "        # store the coefficients and intercepts of the model in the arrays\n",
    "        coef[i] = lr.coef_\n",
    "        intercept[i] = lr.intercept_\n",
    "    n_samples, n_features = X_test.shape    \n",
    "    # create an array to store the probabilities of each class for each sample\n",
    "    prob = np.zeros((n_samples, n_classes))    \n",
    "    for i in range(n_classes):\n",
    "        z = XLT[i].dot(coef[i]) + intercept[i]\n",
    "        prob[:, i] = z     \n",
    "    ans = np.argmax(prob, axis=1)\n",
    "    y_pred_test = accuracy_score(ans, y_test)    \n",
    "    ## ----------此处结束计算时间----------\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    timekeeping_SC.append(end_time - start_time)\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2935ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneVsOthers Stacking\n",
    "def Stacking(X, y, X_test,y_test):\n",
    "    n_classifiers = 3\n",
    "    n_features = X.shape[1]\n",
    "    n_classes = int(n_features/n_classifiers)\n",
    "    coef = np.zeros((n_classes, n_features))\n",
    "    intercept = np.zeros(n_classes)\n",
    "    \n",
    "    ## ----------此处开始计算时间----------\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        y_bin = np.where(y == i, 1, 0)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X, y_bin)\n",
    "        coef[i] = lr.coef_\n",
    "        intercept[i] = lr.intercept_\n",
    "    n_samples, n_features = X_test.shape    \n",
    "    prob = np.zeros((n_samples, n_classes))    \n",
    "    for i in range(n_classes):\n",
    "        z = X_test.dot(coef[i]) + intercept[i]\n",
    "        prob[:, i] = z\n",
    "        \n",
    "    ans = np.argmax(prob, axis=1)\n",
    "    y_pred_test = accuracy_score(ans, y_test)\n",
    "    ## ----------此处结束计算时间----------\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    timekeeping_S.append(end_time - start_time)\n",
    "    return y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee29cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking_predict(X_train,y_train,X_test,y_test,clf):\n",
    "    b1_train = clf[0].predict_proba(X_train)\n",
    "    b2_train = clf[1].predict_proba(X_train)\n",
    "    b3_train = clf[2].predict_proba(X_train)\n",
    "    b_train = np.concatenate((b1_train, b2_train, b3_train), axis=1)\n",
    "\n",
    "    b1_test = clf[0].predict_proba(X_test)\n",
    "    b2_test = clf[1].predict_proba(X_test)\n",
    "    b3_test = clf[2].predict_proba(X_test)\n",
    "    b_test =  np.concatenate((b1_test, b2_test, b3_test), axis=1)\n",
    "\n",
    "    # 返回预测结果\n",
    "    y_pred_test = Stacking(b_train,y_train,b_test,y_test)  \n",
    "    \n",
    "    return (y_pred_test)\n",
    "\n",
    "def StackingC_predict(X_train,y_train,X_test,y_test,clf):\n",
    "    b1_train = clf[0].predict_proba(X_train)\n",
    "    b2_train = clf[1].predict_proba(X_train)\n",
    "    b3_train = clf[2].predict_proba(X_train)\n",
    "    b_train = np.concatenate((b1_train, b2_train, b3_train), axis=1)\n",
    "\n",
    "    b1_test = clf[0].predict_proba(X_test)\n",
    "    b2_test = clf[1].predict_proba(X_test)\n",
    "    b3_test = clf[2].predict_proba(X_test)\n",
    "    b_test =  np.concatenate((b1_test, b2_test, b3_test), axis=1)\n",
    "\n",
    "    # 返回预测结果\n",
    "    yC_pred_test = StackingC(b_train,y_train,b_test,y_test)\n",
    "    \n",
    "    return (yC_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ad643c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入一个以CSV为后缀的文件路径：soybean.csv\n"
     ]
    }
   ],
   "source": [
    "#数据录入\n",
    "try:\n",
    "    url = input(\"请输入一个以CSV为后缀的文件路径：\")  #此处为输入数据集的路径url\n",
    "    if not url.endswith(\".csv\"):\n",
    "        raise ValueError(\"输入的文件名不是CSV格式\")\n",
    "\n",
    "    if not os.path.isfile(url):\n",
    "        raise FileNotFoundError(\"找不到该文件\")\n",
    "             \n",
    "    df = pd.read_csv(url,header=None)\n",
    "\n",
    "    X = df.iloc[:, 1:].values\n",
    "    y = df.iloc[:, 0].values\n",
    "\n",
    "    #过滤掉过少的类别\n",
    "    X, y = filter_by_class_size(X, y, 2)\n",
    "    #对y重新编号\n",
    "    y = pd.factorize(y)[0]\n",
    "\n",
    "    category = np.unique(y).size   #y的类别数\n",
    "    sample_num = y.shape[0]  # 样本总数\n",
    "    # pd.DataFrame(y).value_counts()\n",
    "\n",
    "except (ValueError, FileNotFoundError) as e:\n",
    "    print(\"出现错误：\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92b0c37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "timekeeping_E = []\n",
    "timekeeping_S = []\n",
    "timekeeping_SC = []\n",
    "# loop20\n",
    "loop20_base_predict_test = []\n",
    "loop20_Euclidean_predict = []\n",
    "loop20_simple_weight_predict = []\n",
    "loop20_averageWeight_predict = []\n",
    "loop20_S_predict = []\n",
    "loop20_SC_predict = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb27cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    # 数据5折交叉划分  \n",
    "    '''\n",
    "        input: sample_num->样本总数\n",
    "               X->特征矩阵\n",
    "               y->标签向量\n",
    "        output:train_for_model->训练基模型集\n",
    "               train_for_weight->训练集成模型集\n",
    "               test_set->测试集\n",
    "            '''\n",
    "    np.random.seed(i+1) # 设置随机种子\n",
    "    index = np.arange(sample_num) # 生成索引数组\n",
    "    np.random.shuffle(index) # 打乱索引数组\n",
    "    X = X[index] # 按照打乱后的索引重新排列特征矩阵\n",
    "    y = y[index] # 按照打乱后的索引重新排列标签向量\n",
    "\n",
    "    # 将数据集平均分成5份\n",
    "    X_subsets = np.array_split(X, 5) # 得到一个列表，包含5个子矩阵\n",
    "    y_subsets = np.array_split(y, 5) # 得到一个列表，包含5个子向量\n",
    "\n",
    "    train_for_model = []\n",
    "    train_for_weight = []\n",
    "    test_set = []\n",
    "    # 循环5次，每次选择一个子集作为测试集，其余4个子集作为训练集\n",
    "    for i in range(5):\n",
    "        X_test = X_subsets[i] # 第i个子矩阵作为测试特征矩阵\n",
    "        y_test = y_subsets[i] # 第i个子向量作为测试标签向量\n",
    "        X_train = np.concatenate(X_subsets[:i] + X_subsets[i+1:]) # 其余4个子矩阵合并作为训练特征矩阵\n",
    "        y_train = np.concatenate(y_subsets[:i] + y_subsets[i+1:]) # 其余4个子向量合并作为训练标签向量\n",
    "\n",
    "        # 对每个训练集使用itertools.combinations函数生成所有可能的两两组合，并将它们存储在一个列表中\n",
    "        combinations = itertools.combinations(range(4), 2) # 得到一个迭代器\n",
    "        comb_list = list(combinations) # 将迭代器转换为列表\n",
    "\n",
    "        X_subsets_train = np.array_split(X_train, 4) # 得到一个列表\n",
    "        y_subsets_train = np.array_split(y_train, 4) # 得到一个列表\n",
    "        # 从这个列表中选择6种不同的组合，并根据这些组合从训练特征矩阵和训练标签向量中提取相应的子集，\n",
    "        # 并将它们合并作为X_train_for_model和X_train_for_weight\n",
    "        for j in range(6):\n",
    "            comb = comb_list[j] # 根据索引获取对应的组合\n",
    "            comb_r = comb_list[5-j] # 根据索引获取对应的组合\n",
    "            # 根据组合从训练特征矩阵和训练标签向量中提取相应的子集，并将它们合并作为trainformodel和trainforweight\n",
    "            X_train_1 = X_subsets_train[comb[0]] # 第comb[0]部分作为第一个训练特征\n",
    "            y_train_1 = y_subsets_train[comb[0]] # 第comb[0]部分作为第一个训练标签\n",
    "            X_train_2 = X_subsets_train[comb[1]] # 第comb[1]部分作为第二个训练特征\n",
    "            y_train_2 = y_subsets_train[comb[1]] # 第comb[1]部分作为第二个训练标签\n",
    "\n",
    "            X_train_3 = X_subsets_train[comb_r[0]] # 第comb[0]部分作为第三个训练特征\n",
    "            y_train_3 = y_subsets_train[comb_r[0]] # 第comb[0]部分作为第三个训练标签\n",
    "            X_train_4 = X_subsets_train[comb_r[1]] # 第comb[1]部分作为第四个训练特征\n",
    "            y_train_4 = y_subsets_train[comb_r[1]] # 第comb[1]部分作为第四个训练标签\n",
    "\n",
    "            # 将它们合并\n",
    "            X_train_model = np.concatenate([X_train_1 ,X_train_2]) # trainformodel特征矩阵\n",
    "            y_train_model = np.concatenate([y_train_1 ,y_train_2]) # trainformodel标签向量\n",
    "\n",
    "            X_train_weight = np.concatenate([X_train_3 ,X_train_4]) # trainforweight特征矩阵\n",
    "            y_train_weight = np.concatenate([y_train_3 ,y_train_4]) # trainforweight标签向量\n",
    "\n",
    "            train_for_model.append((X_train_model,y_train_model))\n",
    "            train_for_weight.append((X_train_weight,y_train_weight))\n",
    "            test_set.append((X_test,y_test))\n",
    "\n",
    "    #--模型训练--\n",
    "    '''\n",
    "        input:train_for_model\n",
    "        output:model_set->模型集\n",
    "    '''\n",
    "    model_Set = []\n",
    "    clf1 = DecisionTreeClassifier(min_samples_leaf=5)\n",
    "    clf2 = SVC(probability=True)\n",
    "    clf3 = LogisticRegression()\n",
    "    for turn in range(30):\n",
    "        X_train_model = train_for_model[turn][0]\n",
    "        y_train_model = train_for_model[turn][1]\n",
    "        for clf in (clf1, clf2, clf3):\n",
    "            clf.fit(X_train_model,y_train_model)\n",
    "        model_Set.append([clf1,clf2,clf3])\n",
    "\n",
    "    # --模型评估--\n",
    "    base_predict_test = []\n",
    "    Euclidean_predict = []\n",
    "    simple_weight_predict = []\n",
    "    averageWeight_predict = []\n",
    "    S_predict = []\n",
    "    SC_predict = []\n",
    "\n",
    "    for turn in range(30):\n",
    "        X_train_weight = train_for_weight[turn][0]\n",
    "        y_train_weight = train_for_weight[turn][1]\n",
    "        X_test = test_set[turn][0]\n",
    "        y_test = test_set[turn][1]\n",
    "        model_set = model_Set[turn]\n",
    "\n",
    "        # 基分类器测试结果\n",
    "        base_predict_test.append(get_base_predict(X_test,y_test,model_set))\n",
    "        # Euvlidean训练效果,# Euvlidean测试效果\n",
    "        Euclidean_predict.append(Euclidean(X_train_weight,y_train_weight,X_test,y_test,model_set))\n",
    "        # 权重表训练效果,# 权重表测试效果\n",
    "        simple_weight_predict.append(simple_computer_weight(X_train_weight,y_train_weight,X_test,y_test,model_set))\n",
    "        # 平均权重训练效果,# 平均权重测试效果\n",
    "        averageWeight_predict.append(averageWeight(X_train_weight,y_train_weight,X_test,y_test,model_set))\n",
    "        # Stacking && StackingC 预测结果\n",
    "        S_predict.append(Stacking_predict(X_train_weight,y_train_weight,X_test,y_test,model_set))\n",
    "        SC_predict.append(StackingC_predict(X_train_weight,y_train_weight,X_test,y_test,model_set))\n",
    "\n",
    "    loop20_base_predict_test.append(np.mean(np.array(base_predict_test),axis=0))\n",
    "    loop20_Euclidean_predict.append(np.mean(np.array(Euclidean_predict),axis=0))\n",
    "    loop20_simple_weight_predict.append(np.mean(np.array(simple_weight_predict),axis=0))\n",
    "    loop20_averageWeight_predict.append(np.mean(np.array(averageWeight_predict),axis=0))\n",
    "    loop20_S_predict.append(np.mean(np.array(S_predict),axis=0))\n",
    "    loop20_SC_predict.append(np.mean(np.array(SC_predict),axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b58d356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基分类器预测准确度度量: [0.8049839  0.87769    0.94035745] \n",
      "Euclidean加权预测准确度度量: 0.9399804994990697 \n",
      "权重表预测准确度度量: 0.9399804994990697 \n",
      "平均权重预测准确度度量: 0.9311329969944181 \n",
      "Stacking预测准确度度量: 0.9419784957778733 \n",
      "StackingC预测准确度度量 0.9435117897523974\n"
     ]
    }
   ],
   "source": [
    "# 分类准确率比较\n",
    "\n",
    "# 基分类器预测准确度度量\n",
    "ansloop20_base_predict_test = np.mean(np.array(loop20_base_predict_test),axis=0)\n",
    "# Euclidean加权预测准确度度量\n",
    "ans_loop20_Euclidean_predict = np.mean(np.array(loop20_Euclidean_predict),axis=0)\n",
    "# 权重表预测准确度度量\n",
    "ans_loop20_simple_weight_predict = np.mean(np.array(loop20_simple_weight_predict),axis=0)[1]\n",
    "# 平均权重预测准确度度量\n",
    "ans_loop20_averageWeight_predict = np.mean(np.array(loop20_averageWeight_predict),axis=0)[1]\n",
    "# Stacking预测准确度度量\n",
    "ans_loop20_S_predict = np.mean(np.array(loop20_S_predict),axis=0)\n",
    "# StackingC预测准确度度量\n",
    "ans_loop20_SC_predict = np.mean(np.array(loop20_SC_predict),axis=0)\n",
    "print(\"基分类器预测准确度度量:\",ansloop20_base_predict_test,\"\\nEuclidean加权预测准确度度量:\",ans_loop20_Euclidean_predict,\n",
    "     \"\\n权重表预测准确度度量:\",ans_loop20_simple_weight_predict,\"\\n平均权重预测准确度度量:\",ans_loop20_averageWeight_predict,\n",
    "     \"\\nStacking预测准确度度量:\",ans_loop20_S_predict,\"\\nStackingC预测准确度度量\",ans_loop20_SC_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47acbc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean加权时间开销: 0.0007453941666680445 \n",
      "Stacking加权时间开销: 0.013613947833332153 \n",
      "StackingC加权时间开销: 0.003884173666665447\n"
     ]
    }
   ],
   "source": [
    "#时间开销比较\n",
    "\n",
    "# Euclidean加权时间开销\n",
    "ans_timekeeping_E = np.mean(timekeeping_E)\n",
    "# Stacking加权时间开销\n",
    "ans_timekeeping_S = np.mean(timekeeping_S)\n",
    "# StackingC加权时间开销\n",
    "ans_timekeeping_SC = np.mean(timekeeping_SC)\n",
    "print(\"Euclidean加权时间开销:\",ans_timekeeping_E,\"\\nStacking加权时间开销:\",ans_timekeeping_S,\n",
    "      \"\\nStackingC加权时间开销:\",ans_timekeeping_SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2371f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
